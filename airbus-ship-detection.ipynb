{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, UpSampling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import MeanIoU\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = (256, 256, 3)  # Input shape of the images\nbatch_size = 16  # Number of samples per gradient update\nepochs = 2  # Number of iterations over the entire dataset","metadata":{"execution":{"iopub.status.busy":"2023-06-02T08:45:04.196138Z","iopub.execute_input":"2023-06-02T08:45:04.196804Z","iopub.status.idle":"2023-06-02T08:45:04.202204Z","shell.execute_reply.started":"2023-06-02T08:45:04.196775Z","shell.execute_reply":"2023-06-02T08:45:04.201332Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Path to the dataset folders\ntrain_folder = \"/kaggle/input/airbus-ship-detection/train_v2\"\ntest_folder = \"/kaggle/input/airbus-ship-detection/test_v2\"\ncsv_path = \"/kaggle/input/airbus-ship-detection/train_ship_segmentations_v2.csv\"\n\n# Load the ship segmentation annotations from the CSV file\ndf = pd.read_csv(csv_path)\n\n# Remove rows with missing annotations\ndf = df.dropna()\n\n# Split the dataset into training and validation sets\ntrain_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n\n# Function to encode the ship segmentation masks\ndef encode_mask(mask):\n    pixels = mask.strip().split()\n    pixels = [int(p) for p in pixels]\n    mask = np.zeros(input_shape[:2])\n    for i in range(len(pixels) // 2):\n        start = pixels[2 * i] - 1\n        length = pixels[2 * i + 1]\n        mask[start : start + length] = 1\n    return mask\n\n# Function to decode the ship segmentation masks\ndef decode_mask(mask):\n    if isinstance(mask, list):\n        mask = np.array(mask)\n    pixels = []\n    current_pixel = 0\n    started = False\n    for i in range(mask.shape[0]):\n        if np.any(mask[i] == 1) and not started:\n            pixels.append(i + 1)\n            started = True\n            current_pixel = 1\n        elif np.any(mask[i] == 1) and started:\n            current_pixel += 1\n        elif np.any(mask[i] == 0) and started:\n            pixels.append(current_pixel)\n            started = False\n            current_pixel = 0\n    if started:\n        pixels.append(current_pixel)\n    return \" \".join(str(p) for p in pixels)\n\n\n# Function to load and preprocess an image\ndef load_image(image_id, folder):\n    image_path = os.path.join(folder, image_id)\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, input_shape[:2])\n    image = image / 255.0\n    return image\n\n# Function to load and preprocess the masks\ndef load_mask(image_id):\n    mask_df = df[df[\"ImageId\"] == image_id]\n    masks = np.zeros(input_shape[:2])\n    for _, row in mask_df.iterrows():\n        mask = encode_mask(row[\"EncodedPixels\"])\n        masks = np.maximum(masks, mask)\n    masks = np.expand_dims(masks, axis=-1)\n    return masks\n\n# Function to generate a batch of images and masks\ndef generate_batch(image_ids, folder):\n    while True:\n        for batch_start in range(0, len(image_ids), batch_size):\n            batch_ids = image_ids[batch_start : batch_start + batch_size]\n            images = []\n            masks = []\n            for image_id in batch_ids:\n                image = load_image(image_id, folder)\n                mask = load_mask(image_id)\n                images.append(image)\n                masks.append(mask)\n            yield np.array(images), np.array(masks)\n\n# Generate training and validation data generators\ntrain_image_ids = train_df[\"ImageId\"].values\nval_image_ids = val_df[\"ImageId\"].values\ntrain_generator = generate_batch(train_image_ids, train_folder)\nval_generator = generate_batch(val_image_ids, train_folder)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-02T08:45:04.203810Z","iopub.execute_input":"2023-06-02T08:45:04.204405Z","iopub.status.idle":"2023-06-02T08:45:05.274461Z","shell.execute_reply.started":"2023-06-02T08:45:04.204374Z","shell.execute_reply":"2023-06-02T08:45:05.273426Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate\n\ndef build_simple_unet(input_shape):\n    inputs = Input(input_shape)\n    \n    # Encoder\n    conv1 = Conv2D(32, 3, activation=\"relu\", padding=\"same\")(inputs)\n    conv1 = Conv2D(32, 3, activation=\"relu\", padding=\"same\")(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n    \n    conv2 = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(pool1)\n    conv2 = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    \n    conv3 = Conv2D(128, 3, activation=\"relu\", padding=\"same\")(pool2)\n    conv3 = Conv2D(128, 3, activation=\"relu\", padding=\"same\")(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    \n    conv4 = Conv2D(256, 3, activation=\"relu\", padding=\"same\")(pool3)\n    conv4 = Conv2D(256, 3, activation=\"relu\", padding=\"same\")(conv4)\n    drop4 = Dropout(0.5)(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n    \n    conv5 = Conv2D(512, 3, activation=\"relu\", padding=\"same\")(pool4)\n    conv5 = Conv2D(512, 3, activation=\"relu\", padding=\"same\")(conv5)\n    drop5 = Dropout(0.5)(conv5)\n    \n    # Decoder\n    up6 = Conv2D(256, 2, activation=\"relu\", padding=\"same\")(\n        UpSampling2D(size=(2, 2))(drop5)\n    )\n    merge6 = concatenate([drop4, up6], axis=3)\n    conv6 = Conv2D(256, 3, activation=\"relu\", padding=\"same\")(merge6)\n    conv6 = Conv2D(256, 3, activation=\"relu\", padding=\"same\")(conv6)\n    \n    up7 = Conv2D(128, 2, activation=\"relu\", padding=\"same\")(\n        UpSampling2D(size=(2, 2))(conv6)\n    )\n    merge7 = concatenate([conv3, up7], axis=3)\n    conv7 = Conv2D(128, 3, activation=\"relu\", padding=\"same\")(merge7)\n    conv7 = Conv2D(128, 3, activation=\"relu\", padding=\"same\")(conv7)\n    \n    up8 = Conv2D(64, 2, activation=\"relu\", padding=\"same\")(\n        UpSampling2D(size=(2, 2))(conv7)\n    )\n    merge8 = concatenate([conv2, up8], axis=3)\n    conv8 = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(merge8)\n    conv8 = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(conv8)\n    \n    up9 = Conv2D(32, 2, activation=\"relu\", padding=\"same\")(\n        UpSampling2D(size=(2, 2))(conv8)\n    )\n    merge9 = concatenate([conv1, up9], axis=3)\n    conv9 = Conv2D(32, 3, activation=\"relu\", padding=\"same\")(merge9)\n    conv9 = Conv2D(32, 3, activation=\"relu\", padding=\"same\")(conv9)\n    \n    outputs = Conv2D(1, 1, activation=\"sigmoid\")(conv9)\n    \n    model = Model(inputs=inputs, outputs=outputs)\n    return model\n\n# Build the simplified U-Net model\nmodel = build_simple_unet(input_shape)\nmodel.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-02T08:47:08.899153Z","iopub.execute_input":"2023-06-02T08:47:08.899590Z","iopub.status.idle":"2023-06-02T08:47:13.696718Z","shell.execute_reply.started":"2023-06-02T08:47:08.899556Z","shell.execute_reply":"2023-06-02T08:47:13.695861Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n                                )]                                                                \n                                                                                                  \n conv2d (Conv2D)                (None, 256, 256, 32  896         ['input_1[0][0]']                \n                                )                                                                 \n                                                                                                  \n conv2d_1 (Conv2D)              (None, 256, 256, 32  9248        ['conv2d[0][0]']                 \n                                )                                                                 \n                                                                                                  \n max_pooling2d (MaxPooling2D)   (None, 128, 128, 32  0           ['conv2d_1[0][0]']               \n                                )                                                                 \n                                                                                                  \n conv2d_2 (Conv2D)              (None, 128, 128, 64  18496       ['max_pooling2d[0][0]']          \n                                )                                                                 \n                                                                                                  \n conv2d_3 (Conv2D)              (None, 128, 128, 64  36928       ['conv2d_2[0][0]']               \n                                )                                                                 \n                                                                                                  \n max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 64)  0           ['conv2d_3[0][0]']               \n                                                                                                  \n conv2d_4 (Conv2D)              (None, 64, 64, 128)  73856       ['max_pooling2d_1[0][0]']        \n                                                                                                  \n conv2d_5 (Conv2D)              (None, 64, 64, 128)  147584      ['conv2d_4[0][0]']               \n                                                                                                  \n max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 128)  0          ['conv2d_5[0][0]']               \n                                                                                                  \n conv2d_6 (Conv2D)              (None, 32, 32, 256)  295168      ['max_pooling2d_2[0][0]']        \n                                                                                                  \n conv2d_7 (Conv2D)              (None, 32, 32, 256)  590080      ['conv2d_6[0][0]']               \n                                                                                                  \n dropout (Dropout)              (None, 32, 32, 256)  0           ['conv2d_7[0][0]']               \n                                                                                                  \n max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 256)  0          ['dropout[0][0]']                \n                                                                                                  \n conv2d_8 (Conv2D)              (None, 16, 16, 512)  1180160     ['max_pooling2d_3[0][0]']        \n                                                                                                  \n conv2d_9 (Conv2D)              (None, 16, 16, 512)  2359808     ['conv2d_8[0][0]']               \n                                                                                                  \n dropout_1 (Dropout)            (None, 16, 16, 512)  0           ['conv2d_9[0][0]']               \n                                                                                                  \n up_sampling2d (UpSampling2D)   (None, 32, 32, 512)  0           ['dropout_1[0][0]']              \n                                                                                                  \n conv2d_10 (Conv2D)             (None, 32, 32, 256)  524544      ['up_sampling2d[0][0]']          \n                                                                                                  \n concatenate (Concatenate)      (None, 32, 32, 512)  0           ['dropout[0][0]',                \n                                                                  'conv2d_10[0][0]']              \n                                                                                                  \n conv2d_11 (Conv2D)             (None, 32, 32, 256)  1179904     ['concatenate[0][0]']            \n                                                                                                  \n conv2d_12 (Conv2D)             (None, 32, 32, 256)  590080      ['conv2d_11[0][0]']              \n                                                                                                  \n up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 256)  0          ['conv2d_12[0][0]']              \n                                                                                                  \n conv2d_13 (Conv2D)             (None, 64, 64, 128)  131200      ['up_sampling2d_1[0][0]']        \n                                                                                                  \n concatenate_1 (Concatenate)    (None, 64, 64, 256)  0           ['conv2d_5[0][0]',               \n                                                                  'conv2d_13[0][0]']              \n                                                                                                  \n conv2d_14 (Conv2D)             (None, 64, 64, 128)  295040      ['concatenate_1[0][0]']          \n                                                                                                  \n conv2d_15 (Conv2D)             (None, 64, 64, 128)  147584      ['conv2d_14[0][0]']              \n                                                                                                  \n up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 12  0          ['conv2d_15[0][0]']              \n                                8)                                                                \n                                                                                                  \n conv2d_16 (Conv2D)             (None, 128, 128, 64  32832       ['up_sampling2d_2[0][0]']        \n                                )                                                                 \n                                                                                                  \n concatenate_2 (Concatenate)    (None, 128, 128, 12  0           ['conv2d_3[0][0]',               \n                                8)                                'conv2d_16[0][0]']              \n                                                                                                  \n conv2d_17 (Conv2D)             (None, 128, 128, 64  73792       ['concatenate_2[0][0]']          \n                                )                                                                 \n                                                                                                  \n conv2d_18 (Conv2D)             (None, 128, 128, 64  36928       ['conv2d_17[0][0]']              \n                                )                                                                 \n                                                                                                  \n up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 64  0          ['conv2d_18[0][0]']              \n                                )                                                                 \n                                                                                                  \n conv2d_19 (Conv2D)             (None, 256, 256, 32  8224        ['up_sampling2d_3[0][0]']        \n                                )                                                                 \n                                                                                                  \n concatenate_3 (Concatenate)    (None, 256, 256, 64  0           ['conv2d_1[0][0]',               \n                                )                                 'conv2d_19[0][0]']              \n                                                                                                  \n conv2d_20 (Conv2D)             (None, 256, 256, 32  18464       ['concatenate_3[0][0]']          \n                                )                                                                 \n                                                                                                  \n conv2d_21 (Conv2D)             (None, 256, 256, 32  9248        ['conv2d_20[0][0]']              \n                                )                                                                 \n                                                                                                  \n conv2d_22 (Conv2D)             (None, 256, 256, 1)  33          ['conv2d_21[0][0]']              \n                                                                                                  \n==================================================================================================\nTotal params: 7,760,097\nTrainable params: 7,760,097\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a directory to save the best model weights\nos.makedirs(\"weights\", exist_ok=True)\ncheckpoint_path = \"/kaggle/input/weights-for-airbus-ship/semantic_segmentation_weights.h5\"","metadata":{"execution":{"iopub.status.busy":"2023-06-02T08:52:47.345121Z","iopub.execute_input":"2023-06-02T08:52:47.345486Z","iopub.status.idle":"2023-06-02T08:52:47.350982Z","shell.execute_reply.started":"2023-06-02T08:52:47.345458Z","shell.execute_reply":"2023-06-02T08:52:47.349970Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Define a checkpoint callback to save the best model weights\ncheckpoint_callback = ModelCheckpoint(\n    checkpoint_path,\n    monitor=\"val_loss\",\n    verbose=1,\n    save_best_only=True,\n    mode=\"min\",\n    save_weights_only=True,\n)\n\n# Train the model\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=len(train_image_ids) // batch_size,\n    epochs=epochs,\n    validation_data=val_generator,\n    validation_steps=len(val_image_ids) // batch_size,\n    callbacks=[checkpoint_callback],\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-01T19:02:20.470071Z","iopub.execute_input":"2023-06-01T19:02:20.470482Z","iopub.status.idle":"2023-06-01T20:36:46.626199Z","shell.execute_reply.started":"2023-06-01T19:02:20.470446Z","shell.execute_reply":"2023-06-01T20:36:46.625020Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Epoch 1/2\n","output_type":"stream"},{"name":"stderr","text":"2023-06-01 19:02:24.309275: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"4086/4086 [==============================] - ETA: 0s - loss: 4.4146 - accuracy: 0.9982\nEpoch 1: val_loss improved from inf to 0.00971, saving model to weights/semantic_segmentation_weights.h5\n4086/4086 [==============================] - 2941s 713ms/step - loss: 4.4146 - accuracy: 0.9982 - val_loss: 0.0097 - val_accuracy: 0.9987\nEpoch 2/2\n4086/4086 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9986\nEpoch 2: val_loss improved from 0.00971 to 0.00968, saving model to weights/semantic_segmentation_weights.h5\n4086/4086 [==============================] - 2676s 654ms/step - loss: 0.0106 - accuracy: 0.9986 - val_loss: 0.0097 - val_accuracy: 0.9987\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import clear_output\n\n# Load the best model weights\nmodel.load_weights(checkpoint_path)\n\n# Function to predict masks for test images\ndef predict_masks(image_ids, folder):\n    masks = []\n    for image_id in image_ids:\n        clear_output(wait=True)\n        image = load_image(image_id, folder)\n        mask = model.predict(np.expand_dims(image, axis=0))[0]\n        mask = (mask > 0.5).astype(np.uint8)\n        masks.append(mask)\n    return masks\n\n# Load the test image IDs\ntest_image_ids = os.listdir(test_folder)\n\n# Predict masks for test images\ntest_masks = predict_masks(test_image_ids, test_folder)\n        \n# Save the predicted masks as submission\nsubmission = pd.DataFrame({\"ImageId\": test_image_ids, \"EncodedPixels\": \"\"})\nfor i, image_id in enumerate(test_image_ids):\n    mask = test_masks[i]\n    encoded_pixels = decode_mask(mask)\n    submission.loc[submission[\"ImageId\"] == image_id, \"EncodedPixels\"] = encoded_pixels\nsubmission.to_csv(\"submission.csv\", index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}